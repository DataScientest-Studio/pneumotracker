{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pneumotracker_func import get_and_create_dirs, build_df, build_train_model, model_smpl, model_cmpl, segment_image, dice_coef_loss, dice_coef, get_heatmap_gradcam, lime_heatmap, lime_outline, plot_interpretability_grid\n",
    "# from Segmentation_func import \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "orig_path, seg_path = r'D:\\MOOCS\\DataScientest\\Projet\\Dataset\\chest_xray\\chest_xray', r'D:\\MOOCS\\DataScientest\\Projet\\UNET\\segmentation'\n",
    "orig_file_ext = 'jpeg'\n",
    "smpl_checkp_name = r'.\\Models\\model_simple_orig_224_rgb.h5'\n",
    "smpl_hist_name = r'.\\Models\\history_simple_orig_224_rgb.csv'\n",
    "seg_model = r'.\\Models\\unet_lung_seg.hdf5'\n",
    "cmpl_orig_checkp_name = r'.\\Models\\model_complex_orig_224_rgb.h5'\n",
    "cmpl_orig_hist_name = r'.\\Models\\history_complex_orig_224_rgb.csv'\n",
    "cmpl_seg_checkp_name = r'.\\Models\\model_complex_seg_224_rgb.h5'\n",
    "cmpl_seg_hist_name = r'.\\Models\\history_complex_seg_224_rgb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Press Enter for each input cell to pass default value.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-argentina",
   "metadata": {},
   "source": [
    "## I. Intialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path, seg_path, orig_file_ext, seg_model = get_and_create_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-bracket",
   "metadata": {},
   "source": [
    "## II. Build dataset DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building dataset DataFrame')\n",
    "\n",
    "df = build_df(path_orig = orig_path,\n",
    "              orig_img_ext = 'jpeg',\n",
    "              path_seg = seg_path,\n",
    "              seg_img_ext = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-angola",
   "metadata": {},
   "source": [
    "#### Necessary to ensure same data split between file systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_all.csv', index_col = 0)\n",
    "df['Filepath_orig'] = df['Filepath_orig'].apply(lambda x: x.replace('../input/chest-xray-pneumonia/chest_xray/chest_xray', orig_path).replace(\"/\", \"\\\\\"))\n",
    "df['Filepath_seg'] = df['Filepath_seg'].apply(lambda x: x.replace('../input/segmentation-finale/segmentation', seg_path).replace(\"/\", \"\\\\\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-stockholm",
   "metadata": {},
   "source": [
    "## III. Building and training simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_checkp_name = input('Input path for simple model checkpoint (XXXX.h5) (default github checkpoint path).\\n') or r'.\\Models\\model_simple_orig_224_rgb.h5'\n",
    "smpl_hist_name = input('Input path for simple model history (XXXX.csv) (default github history path).\\n') or r'.\\Models\\history_simple_orig_224_rgb.csv'\n",
    "\n",
    "train = False\n",
    "\n",
    "if 'smpl_checkp_name' in locals():\n",
    "    if os.path.exists(smpl_checkp_name):\n",
    "        train = True if (input('Simple model checkpoint found. Do you want to retrain model (Y/N, default N)?') or 'N') == 'Y' else False\n",
    "    else:\n",
    "        train = True\n",
    "else:\n",
    "    train = True    \n",
    "\n",
    "X_colname = 'Filepath_orig'\n",
    "Y_colname = 'Label_name'\n",
    "\n",
    "if 'df_test_glob' in locals():\n",
    "    md_smpl_eval, history_smpl, smpl_model_class_rep, smpl_model_conf_mat, smpl_orig_model, df_test_glob = build_train_model(df, X_colname, Y_colname, model_smpl, 2, 32, 30, smpl_checkp_name, smpl_hist_name, train, df_test_glob)\n",
    "else:\n",
    "    md_smpl_eval, history_smpl, smpl_model_class_rep, smpl_model_conf_mat, smpl_orig_model, df_test_glob = build_train_model(df, X_colname, Y_colname, model_smpl, 2, 32, 30, smpl_checkp_name, smpl_hist_name, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_glob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-mentor",
   "metadata": {},
   "source": [
    "#### III.1.Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_smpl.index + 1, history_smpl['accuracy'], color = 'royalblue', linestyle = '--', label = 'Train accuracy')\n",
    "plt.plot(history_smpl.index + 1, history_smpl['val_accuracy'], color = 'red', linestyle = '--', label = 'Val accuracy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xticks([5, 10, 15, 20])\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Training vs val accuracy for simple model', pad = 20)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-travel",
   "metadata": {},
   "source": [
    "#### III.2. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_model_class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-dodge",
   "metadata": {},
   "source": [
    "#### III.3. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_model_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-opportunity",
   "metadata": {},
   "source": [
    "## IV. Building and training complex CNN with original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpl_orig_checkp_name = input('Input path for complex model with original images checkpoint (XXXX.h5) (default github checkpoint path).\\n') or r'.\\Models\\model_complex_orig_224_rgb.h5'\n",
    "cmpl_orig_hist_name = input('Input path for complex model with original images history (XXXX.csv) (default github history path).\\n') or r'.\\Models\\history_complex_orig_224_rgb.csv'\n",
    "\n",
    "train = False\n",
    "\n",
    "if 'cmpl_orig_checkp_name' in locals():\n",
    "    if os.path.exists(cmpl_orig_checkp_name):\n",
    "        train = True if (input('Complex model with original images checkpoint found. Do you want to retrain model (Y/N, default N)?') or 'N') == 'Y' else False\n",
    "    else:\n",
    "        train = True\n",
    "else:\n",
    "    train = True    \n",
    "\n",
    "X_colname = 'Filepath_orig'\n",
    "Y_colname = 'Label_name'\n",
    "\n",
    "if 'df_test_glob' in locals():\n",
    "    md_cmpl_orig_eval, history_cmpl_orig, cmpl_orig_model_class_rep, cmpl_orig_model_conf_mat, cmpl_orig_model, df_test_glob = build_train_model(df, X_colname, Y_colname, model_cmpl, 2, 32, 30, cmpl_orig_checkp_name, cmpl_orig_hist_name, train, df_test_glob)\n",
    "else:\n",
    "    md_cmpl_orig_eval, history_cmpl_orig, cmpl_orig_model_class_rep, cmpl_orig_model_conf_mat, cmpl_orig_model, df_test_glob = build_train_model(df, X_colname, Y_colname, model_cmpl, 2, 32, 30, cmpl_orig_checkp_name, cmpl_orig_hist_name, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_glob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-shareware",
   "metadata": {},
   "source": [
    "#### IV.1. Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cmpl_orig.index, history_cmpl_orig['accuracy'], color = 'royalblue', linestyle = '--', label = 'Train accuracy')\n",
    "plt.plot(history_cmpl_orig.index, history_cmpl_orig['val_accuracy'], color = 'red', linestyle = '--', label = 'Val accuracy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xticks([5, 10, 15, 20])\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Training vs val accuracy for complex model with original images', pad = 20)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-energy",
   "metadata": {},
   "source": [
    "#### IV.2. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpl_orig_model_class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-record",
   "metadata": {},
   "source": [
    "#### IV.3. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-farming",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmpl_orig_model_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-tribune",
   "metadata": {},
   "source": [
    "## V. Segmenting images using UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model = load_model(seg_model, \n",
    "                                custom_objects={'dice_coef_loss': dice_coef_loss,\n",
    "                                                'dice_coef': dice_coef})\n",
    "\n",
    "segmentation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (input('Do you want to segment images with UNET model (Y/N, default N)?\\n') or 'N') == 'Y':\n",
    "    print('Segmenting images and saving to', seg_path, '...')\n",
    "    for dirname, _, filenames in os.walk(orig_path):\n",
    "        for filename in tqdm(filenames):\n",
    "            if ('.' + orig_file_ext) in filename:\n",
    "                segment_image(segmentation_model, os.path.join(dirname, filename), dirname.replace(orig_path, seg_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-luxury",
   "metadata": {},
   "source": [
    "## VI. Building and training complex CNN with segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpl_seg_checkp_name = input('Input path for complex model with segmented images checkpoint (XXXX.h5) (default github checkpoint path).\\n') or r'.\\Models\\model_complex_seg_224_rgb.h5'\n",
    "cmpl_seg_hist_name = input('Input path for complex model with segmented history (XXXX.csv) (default github history path).\\n') or r'.\\Models\\history_complex_seg_224_rgb.csv'\n",
    "\n",
    "train = False\n",
    "\n",
    "if 'smpl_checkp_name' in locals():\n",
    "    if os.path.exists(cmpl_seg_checkp_name):\n",
    "        train = True if (input('Complex model with segmented checkpoint found. Do you want to retrain model (Y/N, default N)?\\n') or 'N') == 'Y' else False\n",
    "    else:\n",
    "        train = True\n",
    "else:\n",
    "    train = True    \n",
    "\n",
    "X_colname = 'Filepath_seg'\n",
    "Y_colname = 'Label_name'\n",
    "\n",
    "if 'df_test_glob' in locals():\n",
    "    md_cmpl_seg_eval, history_cmpl_seg, cmpl_seg_model_class_rep, cmpl_seg_model_conf_mat, cmpl_seg_model, df_test_glob = build_train_model(df, X_colname, Y_colname, model_cmpl, 2, 32, 30, cmpl_seg_checkp_name, cmpl_seg_hist_name, train, df_test_glob)\n",
    "else:\n",
    "    md_cmpl_seg_eval, history_cmpl_seg, cmpl_seg_model_class_rep, cmpl_seg_model_conf_mat, cmpl_seg_model, df_test_glob = build_train_model(df, X_colname, Y_colname, model_cmpl, 2, 32, 30, cmpl_seg_checkp_name, cmpl_seg_hist_name, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_glob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-middle",
   "metadata": {},
   "source": [
    "#### VI.1. Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cmpl_seg.index + 1, history_cmpl_seg['accuracy'], color = 'royalblue', linestyle = '--', label = 'Train accuracy')\n",
    "plt.plot(history_cmpl_seg.index + 1, history_cmpl_seg['val_accuracy'], color = 'red', linestyle = '--', label = 'Val accuracy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xticks([5, 10, 15, 20])\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Training vs val accuracy for complex model with segmented images', pad = 20)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-tumor",
   "metadata": {},
   "source": [
    "#### VI.2. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpl_seg_model_class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-premises",
   "metadata": {},
   "source": [
    "#### VI.3. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-celtic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmpl_seg_model_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-gather",
   "metadata": {},
   "source": [
    "## VII. Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_orig = ['person34_virus_76.jpeg', 'person39_bacteria_198.jpeg',\n",
    "                 'person78_bacteria_385.jpeg', 'person83_bacteria_409.jpeg']\n",
    "img_list_seg = ['person34_virus_76.png', 'person39_bacteria_198.png',\n",
    "                'person78_bacteria_385.png', 'person83_bacteria_409.png']\n",
    "\n",
    "smpl_orig_model_last_conv = 'conv2d_1'\n",
    "cmpl_orig_model_last_conv = 'conv2d_29'\n",
    "cmpl_seg_model_last_conv = 'conv2d_169'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-encounter",
   "metadata": {},
   "source": [
    "#### VII.1. Simple model with original images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-infrastructure",
   "metadata": {},
   "source": [
    "##### VII.1.a. Grad-Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interpretability_grid('gradcam',\n",
    "                           smpl_orig_model,\n",
    "                           df_test_glob,\n",
    "                           filepath_col = 'Filepath_orig',\n",
    "                           filename_col = 'Filename_orig',\n",
    "                           class_col = 'Label_name',\n",
    "                           pred_col = 'predicted_str_smpl_orig',\n",
    "                           img_list = img_list_orig,\n",
    "                           nb_img = None,\n",
    "                           last_conv_layer_name = smpl_orig_model_last_conv,\n",
    "                           grad_quant = 0.5,\n",
    "                           alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-acrylic",
   "metadata": {},
   "source": [
    "##### VII.1.b. Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-portrait",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_interpretability_grid('lime',\n",
    "                           smpl_orig_model,\n",
    "                           df_test_glob,\n",
    "                           filepath_col = 'Filepath_orig',\n",
    "                           filename_col = 'Filename_orig',\n",
    "                           class_col = 'Label_name',\n",
    "                           pred_col = 'predicted_str_smpl_orig',\n",
    "                           img_list = img_list_orig,\n",
    "                           nb_img = None,\n",
    "                           last_conv_layer_name = smpl_orig_model_last_conv,\n",
    "                           grad_quant = 0.5,\n",
    "                           alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-diameter",
   "metadata": {},
   "source": [
    "#### VII.2. Complex model with original images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-healing",
   "metadata": {},
   "source": [
    "##### VII.2.a. Grad-Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interpretability_grid('gradcam',\n",
    "                           cmpl_seg_model,\n",
    "                           df_test_glob,\n",
    "                           filepath_col = 'Filepath_orig',\n",
    "                           filename_col = 'Filename_orig',\n",
    "                           class_col = 'Label_name',\n",
    "                           pred_col = 'predicted_str_cmpl_orig',\n",
    "                           img_list = img_list_orig,\n",
    "                           nb_img = None,\n",
    "                           last_conv_layer_name = cmpl_orig_model_last_conv,\n",
    "                           grad_quant = 0.5,\n",
    "                           alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-evolution",
   "metadata": {},
   "source": [
    "##### VII.2.b. Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-armenia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_interpretability_grid('lime',\n",
    "                           cmpl_orig_model,\n",
    "                           df_test_glob,\n",
    "                           filepath_col = 'Filepath_orig',\n",
    "                           filename_col = 'Filename_orig',\n",
    "                           class_col = 'Label_name',\n",
    "                           pred_col = 'predicted_str_cmpl_orig',\n",
    "                           img_list = img_list_orig,\n",
    "                           nb_img = None,\n",
    "                           last_conv_layer_name = cmpl_orig_model_last_conv,\n",
    "                           grad_quant = 0.5,\n",
    "                           alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-hepatitis",
   "metadata": {},
   "source": [
    "#### VII.3. Complex model with segmented images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-immune",
   "metadata": {},
   "source": [
    "##### VII.3.a. Grad-Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interpretability_grid('gradcam',\n",
    "                           cmpl_seg_model,\n",
    "                           df_test_glob,\n",
    "                           filepath_col = 'Filepath_seg',\n",
    "                           filename_col = 'Filename_seg',\n",
    "                           class_col = 'Label_name',\n",
    "                           pred_col = 'predicted_str_cmpl_seg',\n",
    "                           img_list = img_list_seg,\n",
    "                           nb_img = None,\n",
    "                           last_conv_layer_name = cmpl_seg_model_last_conv,\n",
    "                           grad_quant = 0.5,\n",
    "                           alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-alias",
   "metadata": {},
   "source": [
    "##### VII.3.b. Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-escape",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_interpretability_grid('lime',\n",
    "                           cmpl_seg_model,\n",
    "                           df_test_glob,\n",
    "                           filepath_col = 'Filepath_seg',\n",
    "                           filename_col = 'Filename_seg',\n",
    "                           class_col = 'Label_name',\n",
    "                           pred_col = 'predicted_str_cmpl_seg',\n",
    "                           img_list = img_list_seg,\n",
    "                           nb_img = None,\n",
    "                           last_conv_layer_name = cmpl_seg_model_last_conv,\n",
    "                           grad_quant = 0.5,\n",
    "                           alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-scanner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
